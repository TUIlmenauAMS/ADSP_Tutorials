{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "livereveal": {
      "rise": {
        "height": "90%",
        "width": "90%"
      },
      "scroll": true,
      "theme": "sky",
      "transition": "zoom"
    },
    "colab": {
      "name": "ADSP_14_Prediction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_yvPBEHkAr5"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/images/adsp_logo.png?raw=1\">\n",
        "</center>\n",
        "\n",
        "### Prof. Dr. -Ing. Gerald Schuller <br> Jupyter Notebook: Renato Profeta\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYPTDNEslEZm"
      },
      "source": [
        "# Configurations for Google Colab\r\n",
        "if 'google.colab' in str(get_ipython()):\r\n",
        "    print('Running on CoLab')\r\n",
        "    !git clone https://github.com/GuitarsAI/ADSP_Tutorials.git \r\n",
        "    path=\"./ADSP_Tutorials\"\r\n",
        "else:\r\n",
        "    print('Not running on CoLab')\r\n",
        "    path=\".\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcepZaBdkAsF"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "BbySQpUDkAsF"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fKrlRUFPrDg\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDR-lnbskAsG"
      },
      "source": [
        "Prediction can be seen as a special case of a Wiener filter, where the noise of our signal corresponds to a shift of our signal into the past. Our goal is to make a “good” estimation of the present sample of our signal, based on **past signal samples**. “Good” here means, again in a mean squared error sense.\n",
        "\n",
        "Basically we can now take our Wiener Filter formulation, and specialize it to this case. Looking at our matrix formulation, we get\n",
        "\n",
        "$$\\large\n",
        " \\left [ \\matrix{ 0 & x(0) \\\\ x(0) & x(1) \\\\ x(1) & x(2) \\\\ \\vdots & \\vdots }  \\right ] \\cdot \\left [ \\matrix{h(2) \\\\ h(1) }  \\right ]  = \\left [ \\matrix{x(1) \\\\ x(2) \\\\ x(3)\\\\ \\vdots }  \\right ]    \n",
        "$$\n",
        "\n",
        "<center>\n",
        "or\n",
        "</center>\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol A \\cdot \\boldsymbol h^T = \\boldsymbol x$$\n",
        "\n",
        "This means, the input to our filter is always starting at one sample in the past, going down further into the past.  Its goal is to estimate or “predict” the next coming sample. Basically this means that instead of additive white noise, our **distortion** is now a **delay** operator (fortunately, this is a linear operator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "IeO_XYzEkAsH"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LllwthmhLQ4\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xS1zrTQkAsH"
      },
      "source": [
        "Now we can again use our approach with pseudo-inverses to obtain our mean-squared error solution,\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol h = (\\boldsymbol A ^T \\cdot \\boldsymbol A) ^{-1} \\boldsymbol A^T \\cdot \\boldsymbol x\n",
        "$$\n",
        "\n",
        "with the matrix $\\boldsymbol A$ now defined as our above matrix. This now also leads to a statistical description, with $\\boldsymbol A ^ {T} \\cdot \\boldsymbol A$ converging to\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol A^T \\cdot A \\rightarrow R_{xx} =  \\left [ \\matrix{ r_{xx(0)} & r_{xx(1)} & r_{xx(2)}  & \\cdots \n",
        "\\\\ r_{xx(1)} & r_{xx(0)} & r_{xx(1)}  & \\cdots \n",
        "\\\\ \\vdots & \\vdots & \\vdots }  \\right ]\n",
        "$$\n",
        "\n",
        "This is plausible, because now y(n) is just the delayed signal, and the auto-correlation function of the delayed signal is identical to the auto-correlation function of the original function. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "iVsNTcMAkAsI"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/A7qWqH4E2HI\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bHAQSGmkAsI"
      },
      "source": [
        "Next we need the cross-correlation $\\boldsymbol A^T \\cdot \\boldsymbol x$. Since we now just have this 1 sample in the future as our target vector, this converges to the auto-correlation vector, starting at **lag 1**,\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol A^T \\cdot \\chi \\rightarrow r_{xx} =  \\left [ \\matrix{ r_{xx(1)} \\\\ r_{xx(2)} \\\\ \\vdots}  \\right ]\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So together we get the solution for our prediction filter as\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol h = (\\boldsymbol R_{xx}) ^{-1} \\boldsymbol r_{xx}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpIKOI0nkAsI"
      },
      "source": [
        "A system which produces the **prediction error** (for instance of part of an encoder) as an output is the following,\n",
        "\n",
        "<center>\n",
        "    <img src='https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/images/Lecture14-1.JPG?raw=1' width='800'>\n",
        "</center>\n",
        "\n",
        "Here, $x(n)$ is the signal to be predicted, $H(z)$ is our prediction filter, whose **coefficents** are obtained with our **Wiener approach** in the last lecture slides,\n",
        "\n",
        "$\\boldsymbol h=\\boldsymbol {(R_{xx})}^{-1}r_{xx}$, where $H(z)$ is simply its z-transform. \n",
        "\n",
        "It works on only past samples (that's why we have the delay element by one sample, $z^{-1}$, before it), $\\hat x(n)$ is our **predicted** signal, and $e(n)=x(n)-\\hat x(n)$ is our **prediction error** signal. Hence, our system which produces the prediction error has the z-domain transfer function of\n",
        "\n",
        "$$\\large\n",
        "H_{perr}(z)=1-z^{-1} \\cdot H(z)\n",
        "$$\n",
        "\n",
        "This can be an **encoder**. Observe that we can **reconstruct** the original signal $x(n)$ in a **decoder** from the prediction error $e(n)$, with the following system,\n",
        "\n",
        "<center>\n",
        "    <img src='https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/images/Lecture14-2.JPG?raw=1' width='800'>\n",
        "</center>\n",
        "    \n",
        "Remember that encoder computed $e(n)=x(n)-\\hat x(n)$.\n",
        "\n",
        "The feedback loop in this system is causal because it only uses **past**, already **reconstructed samples**!\n",
        "\n",
        "Observe that this decoders transfer function is\n",
        "\n",
        "$$\\large\n",
        " {H_{rec}(z)} = \\frac{1}  {1-z^{-1} \\cdot H(z)}=\\frac{1}  {H_{perr}(z)}\n",
        "$$\n",
        "\n",
        "which is exactly the inverse of the encoder, which was to be expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ntjE8lOkAsJ"
      },
      "source": [
        "## Python Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXTR2MkCkAsJ"
      },
      "source": [
        "**Goal:** Construct a prediction filter for Iron Maiden - Aces High speech signal of **order L=10**, which minimizes the mean-squared prediction error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "R-iwvvYKkAsJ"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AQ198XfsHS0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7XI_DYWkAsJ"
      },
      "source": [
        "# Imports\n",
        "import librosa as lbr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Import Speech\n",
        "x , sr = lbr.load(path+'/audio/Iron Maiden - Aces High.mp3', offset=0, duration=28.8)\n",
        "# Normalize Audio\n",
        "x/=np.abs(x).max()\n",
        "# Plot Audio\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x)\n",
        "plt.title('Iron Maiden - Aces High (Intro)')\n",
        "plt.xlabel('samples n')\n",
        "plt.ylabel('Amplitude (Normalized)');\n",
        "plt.grid()\n",
        "# Listen\n",
        "display(ipd.Audio(x, rate = sr ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNNUQrevkAsK"
      },
      "source": [
        "#make x a matrix of ﬂoat type and transpose\n",
        "#it into a column\n",
        "x=np.matrix(x,dtype=float).T\n",
        "#Construct our Matrix A from x:\n",
        "A=np.matrix(np.zeros((100000,10)));\n",
        "for m in range(0,100000):\n",
        "    A[m, :]=np.flipud(x[m+np.arange(10)]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc7_nYazkAsL"
      },
      "source": [
        "#Construct our desired target signal d,\n",
        "#one sample into the future, we\n",
        "#start with the first 10 samples already in the\n",
        "#prediction filter, then the 11th sample is\n",
        "#the frst to be predicted:\n",
        "d = x[np.arange(10,100010)]\n",
        "#Compute the prediction flter:\n",
        "h=np.linalg.inv(A.T*A) * A.T * d;\n",
        "print(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiVfFEGnkAsL"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot((h))\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Impulse Response of our Prediction Filter')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x66itf2BkAsL"
      },
      "source": [
        "Then our prediction filter, with the delay in the encoder becomes (to compare it with the original signal):   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd3nLGhikAsM"
      },
      "source": [
        "hpred = np.vstack([0, (h)])\n",
        "print(hpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLrTpZpukAsM"
      },
      "source": [
        "The predicted values are now obtained by appying these coefficients as an FIR filter:        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQpFh6WkAsM"
      },
      "source": [
        "import scipy.signal as sp\n",
        "xpred = sp.lfilter(np.array(hpred.T)[0],1,np.array(x.T)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6F1xR-ZkAsM"
      },
      "source": [
        "Now we can plot the predicted values on top of the actual original signal values, to see how accurate our prediction is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwBS0OM5kAsN"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x);\n",
        "plt.plot(xpred,'red')\n",
        "plt.legend(('Original','Predicted'), loc='upper right')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Our Speech Wave Form')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCiBtTckAsN"
      },
      "source": [
        "Our corresponding **prediction error** filter (which is in the **encoder**) is:\n",
        "\n",
        "$$\\large\n",
        "H_{perr}(z)=1-z^{-1}\\cdot H(z)$$ \n",
        "\n",
        "in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "GbWME9aGkAsN"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IE_ZCB1gGSQ\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOJMdHt6kAsN"
      },
      "source": [
        "hperr = np.vstack([1, -(h)])\n",
        "print(hperr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQUIIaVpkAsO"
      },
      "source": [
        "The prediction error e(n) is obtained using our prediction error filter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEszu4dgkAsO"
      },
      "source": [
        "e = sp.lfilter(np.array(hperr.T)[0],1,np.array(x.T)[0]);\n",
        "#make a matrix type out of it (row matrix):\n",
        "e=np.matrix(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nraDBENskAsO"
      },
      "source": [
        "Error power per sample:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1zvMSAPkAsO"
      },
      "source": [
        "e*e.T/max(np.shape(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAGf9zgXkAsO"
      },
      "source": [
        "Compare that with the mean squared signal power per sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUzYlvH1kAsP"
      },
      "source": [
        "x.T*x/max(np.shape(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufulkAtHkAsP"
      },
      "source": [
        "Which is more than 10 times as big as the prediction error! Which shows that it works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8cVMylNkAsP"
      },
      "source": [
        "Listen to the error signal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtsF0N7ykAsP"
      },
      "source": [
        "display(ipd.Audio(e[0], rate = sr ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7FNBvclkAsR"
      },
      "source": [
        "Take a look at the signal and it's prediction error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9fDFa2kAsR"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x)\n",
        "plt.plot(e.T,'r')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Our Speech and Prediction Error Wave Forms')\n",
        "plt.legend(('Original', 'Prediction Error'), loc='upper right')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA8IZpcikAsR"
      },
      "source": [
        "The **decoder** uses the reverse filter structure $ H_{rec}=\\frac{1 }{1-z^{-1} \\cdot H(z)}=\\frac{1} {H_{perr}(z)}$,\n",
        "hence we use the following filter command to generate the reconstructed signal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "PvDRaAF9kAsR"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BAz8Kvu4VYA\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nSBx0eWkAsR"
      },
      "source": [
        "xrec = sp.lfilter([1],np.array(hperr.T)[0], np.array(e)[0]);\n",
        "#plot original for comparison:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x,'b')\n",
        "#Plot decoded reconstructed on top in red:\n",
        "plt.plot(xrec,'r')\n",
        "plt.legend(('Original', 'Reconstructed'), loc='upper right')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_z82_KwkAsS"
      },
      "source": [
        "display(ipd.Audio(xrec, rate = sr ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVOIeNP6kAsT"
      },
      "source": [
        "**Observe:** The decoded, reconstructed looks and sound **identical** to the original, as expected. This means we can indeed use it in an encoder-decoder setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMO5sXD8kAsT"
      },
      "source": [
        "## Neural Network Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVI9p1YYkAsT"
      },
      "source": [
        "Again we can also use the numerical optimization of Pytorch instead of our closed form solution from Wiener-Hopf, and a conv1d layer.\n",
        "\n",
        "We also use the **mean squared error** as minimization criteriun or “loss function”. In this case this does not diﬀer from the target of the closed form formulation, and hence we obtain almost the same solution. Here, the desired target signal Y is the audio input signal X, but 1 sample in the future,\n",
        "\n",
        "`X=audio[:-L]) #remove last samples (conv makes it longer again)`\n",
        "\n",
        "```Y=audio[1:]) #remove frst sample, for the signal to predict, 1\n",
        "sample in the future\n",
        "```  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "QdJ-51MgkAsU"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kmArYc5NxJU\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhdmG3HlkAsU"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "__author__ = 'Gerald Schuller'\n",
        "__copyright__ = 'G.S.'\n",
        "\n",
        "\"\"\"\n",
        "Simple program to use a convolutional neural network to obtain a prective coder,\n",
        "using explicit inputs to layers, to enable skip layers.\n",
        "According to: https://keras.io/getting-started/functional-api-guide/\n",
        "With Pytorch\n",
        "For instance according to WCLMS or prediction Boosting\n",
        "\n",
        "\n",
        "Gerald Schuller, November 2018.\n",
        "\n",
        "--- Modified by Renato Profeta to use librosa, March 2020\n",
        "\"\"\"\n",
        ";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AERU59tTkAsU"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io.wavfile as wav\n",
        "import librosa as lbr\n",
        "  \n",
        "if sys.version_info[0] < 3:\n",
        "   # for Python 2\n",
        "   import cPickle as pickle\n",
        "else:\n",
        "   # for Python 3\n",
        "   import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o71oLkoXkAsU"
      },
      "source": [
        "L=12 #filter length\n",
        "dilation=1 #Dilation: upsampling the filter impulse response, new filter length: (L-1)*dilation+1\n",
        "\n",
        "def format_vector2pytorch(vector):\n",
        "    #Function to convert a vector, like a mono audio signal, into a 3-d Tensor X that Keras expects\n",
        "    #Tensor X with shape (batch, signal):\n",
        "    #https://discuss.pytorch.org/t/confused-about-tensor-dimensions-and-batches/4761\n",
        "    X = np.expand_dims(vector, axis=0)  #add batch dimension (here only 1 batch)\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    X=torch.from_numpy(X)\n",
        "    X=X.type(torch.Tensor)\n",
        "    return X\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Define the model. \n",
        "        self.layer1=nn.Sequential(nn.Conv1d(in_channels=1, out_channels=1, kernel_size=L, stride=1, \n",
        "                                            dilation=dilation, padding=dilation*(L-1), bias=False))\n",
        "        #https://pytorch.org/docs/stable/nn.html#conv1d  \n",
        "        # Generate a convolutional neural network model, 1 layer, no bias, linear activation function \n",
        "        # returns: Trainable object\n",
        "        #concatenate data:\n",
        "        #https://discuss.pytorch.org/t/concatenate-layer-output-with-additional-input-data/20462\n",
        "        #input of layer: x, output of layer: out\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIIVprgBkAsU"
      },
      "source": [
        "#Example to find prediction coefficients to minimize the mean absolute error using Python Keras\n",
        "#and 1 Convolutional layer as a predictor.\n",
        "    \n",
        "#Input mono audio signal X:\n",
        "#samplerate, audio = wav.read(\"mspeech.wav\")\n",
        "audio, samplerate = lbr.load(path+\"/audio/Iron Maiden - Aces High.mp3\", duration=28.8)\n",
        "audio/=np.abs(audio).max()\n",
        "    \n",
        "#audiosh=audio[:100000] #shorten the signal for faster optimization,\n",
        "audiosh=audio\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(audiosh)\n",
        "plt.title(\"The Audio Signal to Predict\")\n",
        "plt.grid()\n",
        "    \n",
        "X=format_vector2pytorch(audiosh[:-((L-1)*dilation+1)])      #remove last samples \n",
        "Y=format_vector2pytorch(audiosh[1:]) #remove first sample, for the signal to predict, 1 sample in the future\n",
        "    \n",
        "\n",
        "print(\"Input X.shape=\", X.shape )\n",
        "print(\"Target Y.shape=\", Y.shape)\n",
        "display(ipd.Audio(audio, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57v8DksMkAsV"
      },
      "source": [
        "model = ConvNet()#.to('cpu')\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "#learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters())#, lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rGxSKKBkAsV"
      },
      "source": [
        "for epoch in range(10000):\n",
        "    Ypred=model(X)\n",
        "    loss=loss_fn(Ypred, Y)\n",
        "    if epoch%100==0:\n",
        "        print(epoch, loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "torch.save({'epoch': epoch,'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, \"linpredweights.torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI-BaO6wkAsW"
      },
      "source": [
        "#Processing full length signal:\n",
        "X=format_vector2pytorch(audio[:-((L-1)*dilation+1)])  #remove last samples \n",
        "Y=format_vector2pytorch(audio[1:]) #remove first sample\n",
        "predictions=model(X) # Make Predictions based on the obtained weights, on short audio\n",
        "#mean squared predicton error:\n",
        "err= sum((predictions[0,0,:]-Y[0,0,:])**2)/max(Y.shape)\n",
        "print(\"mean squared prediction error=\", err)\n",
        "#mean signal power:\n",
        "sigpow=sum(X[0,0,:]**2)/max(X.shape)\n",
        "print(\"mean signal power=\", sigpow)\n",
        "print(\"Signal to Error Power Ratio:\", sigpow/err)\n",
        "    \n",
        "ww = model.state_dict()   #read obtained weights\n",
        "print(\"ww=\", ww)\n",
        "#weight format for Conv1d:\n",
        "#[0: filter weights, 1: bias for first layer]\n",
        "#weight: filters of shape: out_channels× in_channelsgroups× kW\n",
        "weights=ww['layer1.0.weight'][0,0,:]\n",
        "print(\"weights= \", weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NTX0HfkAsW"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(Y[0,0,:]))\n",
        "plt.plot(predictions.detach().numpy()[0,0,:])\n",
        "plt.legend(('Original','Predicted'))\n",
        "plt.title('The Original and Predicted Signal')\n",
        "plt.xlabel('Sample')\n",
        "plt.grid()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(Y[0,0,:]))\n",
        "plt.plot(predictions.detach().numpy()[0,0,:]-np.array(Y[0,0,:]))\n",
        "plt.legend(('Original','Prediction Error'))\n",
        "plt.title('The Original and Prediction Error')\n",
        "plt.xlabel('Sample')\n",
        "plt.grid()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(weights))\n",
        "plt.title('The Weights')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVx1nhMUkAsW"
      },
      "source": [
        "# Predictions\n",
        "display(ipd.Audio(predictions.detach().numpy()[0,0,:], rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9y_CrGtkAsX"
      },
      "source": [
        "## Online Adaptation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "zhA9Iuv0kAsX"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6HMbCoPF06o\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI5djm4XkAsX"
      },
      "source": [
        "The previous example calculated the prediction coefficients for the entire speech  file (or the first 100000 samples). But when we look at the signal waveform, we see that its characteristics and hence its statistics is changing, it is **not stationary**.\n",
        "\n",
        "Hence we can expect a prediction improvement if we divide the speech signal into **small pieces** for the computation of the prediction coefficients, pieces which are small enough to show roughly **constant** statistics. In speech coding, those pieces are usually of length 20 ms, and this approach is called **Linear Predictive Coding (LPC)**. Here, the prediction coefficients are calculated usually every 20 ms, and then transmitted alongside the prediction error, from the encoder to the decoder.\n",
        "\n",
        "This also has the advantage that it needs no “training set”, and computes the coefficients from the actual samples in the current block.\n",
        "\n",
        "**Observe** that this also need a very fast optimization, hence the Pytorch approach with the “Adam” optimizer would not be suitable. We use our faster closed form solution instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "TMZoFDc3kAsX"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/j75eozga8ZQ\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE5owRI8kAsY"
      },
      "source": [
        "### Python Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2pU26w5kAsY"
      },
      "source": [
        "Our speech signal is sampled at 32 kHz, hence a block of 20 ms has **640 samples**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "0-3eP9EskAsY"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DIr6SPdK4NA\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNL9NO03kAsY"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal as sp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4ShbhthkAsY"
      },
      "source": [
        "x, samplerate = lbr.load(path+\"/audio/Iron Maiden - Aces High.mp3\", duration=28, sr=32000)\n",
        "x/=np.abs(x).max()\n",
        "print('Audio Length:',np.size(x))\n",
        "display(ipd.Audio(x, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGX85SebkAsa"
      },
      "source": [
        "L=10 #predictor length\n",
        "len0 = np.max(np.size(x))\n",
        "e = np.zeros(np.size(x)) #prediction error variable initialization\n",
        "blocks = np.int(np.floor(len0/640)) #total number of blocks\n",
        "state = np.zeros(L) #Memory state of prediction filter\n",
        "#Building our Matrix A from blocks of length 640 samples and process:\n",
        "h=np.zeros((blocks,L)) #initialize pred. coeff memory\n",
        "\n",
        "\n",
        "for m in range(0,blocks):\n",
        "    A = np.zeros((640-L,L)) #trick: up to 630 to avoid zeros in the matrix\n",
        "    for n in range(0,640-L):\n",
        "        A[n,:] = np.flipud(x[m*640+n+np.arange(L)])\n",
        "\n",
        "    #Construct our desired target signal d, one sample into the future:\n",
        "    d=x[m*640+np.arange(L,640)];\n",
        "    #Compute the prediction filter:\n",
        "    h[m,:] = np.dot(np.dot(np.linalg.pinv(np.dot(A.transpose(),A)), A.transpose()), d)\n",
        "    hperr = np.hstack([1, -h[m,:]])\n",
        "    e[m*640+np.arange(0,640)], state = sp.lfilter(hperr,[1],x[m*640+np.arange(0,640)], zi=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qOYzlKokAsa"
      },
      "source": [
        "#The mean-squared error now is:\n",
        "print (\"The average squared error is:\", np.dot(e.transpose(),e)/np.max(np.size(e)))\n",
        "#The average squared error is: 0.000113347859337\n",
        "#We can see that this is only about 1 / 4 of the previous pred. Error!\n",
        "print (\"Compare that with the mean squared signal power:\", np.dot(x.transpose(),x)/np.max(np.size(x)))\n",
        "#0.00697569381701\n",
        "print (\"The Signal to Error ratio is:\", np.dot(x.transpose(),x)/np.dot(e.transpose(),e))\n",
        "#61.5423516403\n",
        "#So our LPC pred err energy is more than a factor of 61 smaller than the \n",
        "#signal energy!\n",
        "#Listen to the prediction error:\n",
        "display(ipd.Audio(e, rate = samplerate ))\n",
        "\n",
        "#Take a look at the signal and it's prediction error:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x)\n",
        "#plt.hold(True)\n",
        "plt.plot(e,'r')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Normalized Value')\n",
        "plt.legend(('Original','Prediction Error'))\n",
        "plt.title('LPC Coding')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7-nIjewkAsb"
      },
      "source": [
        " Here it can be seen that the prediction error is even smaller than before.\n",
        " \n",
        "The **decoder** works the way as shown in the previous example, and the reconstructed speech can be heard in the end.\n",
        "\n",
        "**LPC** type **coders** are for instance speech coders, where usually 12 coefficients are used for the prediction, and **transmitted as side information** every 20 ms. The prediction error is parameterized and transmitted as parameters with a very low bit rate. This kind of system is used for instance in most digital **cell phones** systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnoj-IfFkAsb"
      },
      "source": [
        "#Decoder:\n",
        "xrek=np.zeros(x.shape) #initialize reconstructed signal memory\n",
        "state = np.zeros(L) #Initialize Memory state of prediction filter\n",
        "for m in range(0,blocks):\n",
        "    hperr = np.hstack([1, -h[m,:]])\n",
        "    #predictive reconstruction filter: hperr from numerator to denominator:\n",
        "    xrek[m*640+np.arange(0,640)] , state = sp.lfilter([1], hperr,e[m*640+np.arange(0,640)], zi=state)\n",
        "\n",
        "#Listen to the reconstructed signal:\n",
        "display(ipd.Audio(xrek, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6dsw6w8kAsc"
      },
      "source": [
        "## Least Mean Squares (LMS) Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "t1WEN6iSkAsd"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CI-Q24AumME\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePbgx_DAkAsd"
      },
      "source": [
        "Unlike the LPC algorithm above, which computes prediction coefficients for a block of samples and transmits these coefficients alongside the prediction error to the receiver, the LMS algorithm updates the prediction coefficients after each sample, but based only on **past** samples. \n",
        "\n",
        "Hence here we need the assumption that the signal statistics does not change much from the past to the present. Since it is based on the past samples, which are also available as decoded samples at the decoder, we do not need to transmit the coefficients to the decoder. Instead, the decoder carries out the same computations in **synchrony with the encoder**.\n",
        "\n",
        "Instead of a matrix formulation, we use an iterative algorithm to come up with a solution for the prediction coefficients $h$ the vector which contains the time-reversed impulse response.\n",
        "\n",
        "To show the dependency on the time $n$, we now call the vector of prediction coefficients $h(n)$, with\n",
        "\n",
        "$$\\large\n",
        "h(n)=[h_0(n),\\ldots ,h_{L-1}(n)]$$\n",
        "\n",
        "Again we would like to **minimize** the **mean quadratic prediction error** (with the prediction error $e(n) = x(n)-\\hat x(n)$),\n",
        "\n",
        "$$\\large\n",
        "E \\left [ (x(n)-\\hat x(n))^2 \\right ]= E \\left[(x(n) - \\sum_ {k=0}^ {L-1} h_k(n)x(n-1-k))^2 \\right]\n",
        "$$\n",
        "\n",
        "Instead of using the closed form solution, which lead to the Wiener-Hopf Solution, we now take an **iterative** approach to approach the minimum of this optimization function.\n",
        "\n",
        "We use the algorithm of **Steepest Descent** (also called **Gradient Descent**), see also http://en.wikipedia.org/wiki/Gradient_descent, to iterate towards the minimum,\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol h(n+1)= \\boldsymbol h(n) - \\alpha \\cdot \\nabla f(\\boldsymbol h(n))\n",
        "$$\n",
        "\n",
        "with **optimization function** as our squared prediction error,<br>\n",
        "\n",
        "$$\\large\n",
        "f(\\boldsymbol h(n))=(x(n) - \\sum_ {k=0} ^ {L-1} h_k(n)x(n-1-k))^2\n",
        "$$\n",
        "\n",
        "**Observe** that we omitted the Expectation operator “E” for simplicity; we expect that after several update steps there will be inherently some averaging. This is also called **“Stochastic Gradient Descent”** We have the Gradient as the row vector<br>\n",
        "\n",
        "$$\\large\n",
        "\\nabla f(n)=\\left[ \\frac{\\partial f(\\boldsymbol h(n))}  {\\partial h_0(n)},...,\\frac{\\partial f(\\boldsymbol h(n))} {\\partial h_{L-1}(n)} \\right]\n",
        "$$\n",
        "\n",
        "and we get the individual derivatives as\n",
        "\n",
        "$$\\large\n",
        "\\frac{\\partial f(\\boldsymbol h(n))} {\\partial h_k(n)}= 2 \\cdot e(n) \\cdot (-x(n-1-k))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfsLMOpWkAsd"
      },
      "source": [
        "So together we obtain the **LMS algorithm** or **update rule** as\n",
        "\n",
        "\n",
        "$$\\large\n",
        "h_k(n+1)= h_k(n)+ \\alpha \\cdot e(n) \\cdot x(n-1-k)  \n",
        "$$\n",
        "\n",
        "for $k=0, \\ldots L-1$, where $\\alpha$ is a tuning parameter (the factor 2 is incorporated into $\\alpha$), with which we can trade off **convergence speed and convergence accuracy**. A derivation or computation of the $\\alpha$ value can be found in the lecture **slide set 15** of our lecture “**Multirate Signal Processing**”.\n",
        "\n",
        "\n",
        "In vector form, this LMS update rule is\n",
        "\n",
        "$$\\large\n",
        "\\boldsymbol h(n+1)= \\boldsymbol h(n) + \\alpha \\cdot e(n) \\cdot \\boldsymbol x(n)$$\n",
        "where $\\boldsymbol x(n)= \\left[x(n-1),x(n-2),...,x(n-L)\\right]$.\n",
        "\n",
        "**Observe** that we need no matrices or matrix inverses in this case, just this simple update rule, and it still works! It still converges to the “correct” coefficients!\n",
        "For the prediction coefficients $h$ we have something like a “**sliding window**” of the past L samples $x(n)$ of our signal.\n",
        "\n",
        "For $\\mu$ there are different “recipes”, for instance the so-called normalized LMS (NLMS) uses the inverse signal power as $\\alpha$. If the signal power is one, then $\\alpha$ can be one. But in general it is subject to “hand tuning”, trial and error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePspuuqYkAsd"
      },
      "source": [
        "### LMS Python Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "rKM3sIe-kAsd"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2ZgnWwKMlT4\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR9ZCHvAkAsd"
      },
      "source": [
        "x, samplerate = lbr.load(path+\"/audio/Iron Maiden - Aces High.mp3\", duration=28, sr=32000)\n",
        "print('Audio Length:',np.size(x))\n",
        "display(ipd.Audio(x, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoeNO0J0kAsf"
      },
      "source": [
        "e = np.zeros(np.size(x))\n",
        "h = np.zeros(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8F9buL1kAsf"
      },
      "source": [
        "#have same 0 starting values as in decoder:\n",
        "x[0:10]=0.0\n",
        "for n in range(10, len(x)):\n",
        "    #prediction error and filter, using the vector of the time reversed IR:\n",
        "    e[n] = x[n] - np.dot(np.flipud(x[n-10+np.arange(0,10)]),(h))\n",
        "    #LMS update rule, according to the definition above:\n",
        "    h = h + 1.0* e[n]*np.flipud(x[n-10+np.arange(0,10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xggjz90okAsg"
      },
      "source": [
        "print( \"Mean squared prediction error:\", np.dot(e, e) /np.max(np.size(e)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYIp8CKCkAsg"
      },
      "source": [
        "display(ipd.Audio(e, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKYpWu1FkAsh"
      },
      "source": [
        "The comparison plot of the original to the prediction error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQPESSKMkAsh"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x)\n",
        "plt.plot(e,'r')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Normalized Sample')\n",
        "plt.title('Least Mean Squares (LMS) Online Adaptation')\n",
        "plt.legend(('Original','Prediction Error'))\n",
        "plt.grid()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kP90UkqkAsh"
      },
      "source": [
        "**Observe:** its prediction error is bigger than in the **LPC** case, but we also don't need to transmit the prediction coefficients as side information.<br>\n",
        "\n",
        "The comparison plot of the original to the prediction error can be seen in above python example \n",
        "\n",
        "For the **decoder** we get the reconstruction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc0NezahkAsh"
      },
      "source": [
        "# Decoder\n",
        "h = np.zeros(10);\n",
        "xrek = np.zeros(np.size(x))\n",
        "\n",
        "\n",
        "for n in range(10, len(x)):\n",
        "    if np.any(np.isnan(h)):\n",
        "        print('n',n)\n",
        "        print('Decoder h:',h)\n",
        "        break\n",
        "    xrek[n] = e[n] + np.dot(np.flipud(xrek[n-10+np.arange(10)]), h)\n",
        "    #LMS update:\n",
        "    h = h + 1 * e[n]*np.flipud(xrek[n-10+np.arange(10)]);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFwmF0L2kAsh"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(xrek)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64VG5_KkAsi"
      },
      "source": [
        "**Sensitivity** of the decoder for transmission **errors**: In the code for the decoder in the LMS update for the predictor h, correctly we need xrek instead of x (since x is not available in the decoder). The slightest computation errors, for instance **rounding errors**, are sufficient to make the decoder diverge and stop working after a few syllables of the speech.  \n",
        "\n",
        "We see that the computed **prediction coefficients differ** in the last digits between encoder and decoder, which is enough for **increasing divergence** between encoder and decoder, until the decoded signal “explodes” (becomes huge from instability).\n",
        "\n",
        "This shows that **LMS is very sensitive to transmission errors**.\n",
        "\n",
        "To avoid at least the computation errors, we need to include quantization in the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfOjBYKvkAsi"
      },
      "source": [
        "## Predictive Encoder with Quantizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "sWCF9xl4kAsi"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9O0G7WlUYvI\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msj8DVLckAsi"
      },
      "source": [
        "<center>\n",
        "    <img src='https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/images/Lecture14-3.jpg?raw=1' width='800'> \n",
        "</center>\n",
        "   \n",
        "Here we can see a predictive encoder with **quantization** of the prediction error. In order to make sure the encoder predictor works on the quantized values, like in the decoder, it uses a **decoder in the encoder** structure, which produces the quantized reconstructed value $Q(x(n))$ (the function Q() here include both, quantizer and de-quantizer).\n",
        "\n",
        "The decoder stays the same, except for the  de-quantization of the prediction error in the beginning:\n",
        "\n",
        "\n",
        "<center>\n",
        "    <img src='https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/images/Lecture14-4.JPG?raw=1' width='800'> \n",
        "</center> \n",
        "\n",
        "\n",
        "Observe: The reconstructed signal x(n) is the same as for the encoder, plus the quantization error from the quantizer:\n",
        "\n",
        "$$\\large\n",
        "Q( x(n) )= e(n) + \\hat{ x}( n) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVzMyXuQkAsi"
      },
      "source": [
        "### LMS with Quantizer Python Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "WybehL14kAsi"
      },
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pWqIUaV_ixU\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuAKDSafkAsj"
      },
      "source": [
        "x, samplerate = lbr.load(path+\"/audio/Iron Maiden - Aces High.mp3\", duration=28, sr=32000)\n",
        "print('Audio Length:',np.size(x))\n",
        "display(ipd.Audio(x, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpwPGUogkAsj"
      },
      "source": [
        "e = np.zeros(np.size(x))\n",
        "xrek=np.zeros(np.size(x));\n",
        "P=0;\n",
        "L=10\n",
        "h = np.zeros(L)\n",
        "#have same 0 starting values as in decoder:\n",
        "x[0:L]=0.0\n",
        "quantstep=0.01;\n",
        "for n in range(L, len(x)):\n",
        "    if n> 41405 and n< 41408:\n",
        "        print('n:',n)\n",
        "        print (\"encoder h: \", h, \"\\ne=\", e)\n",
        "    #prediction error and filter, using the vector of the time reversed IR:\n",
        "    #predicted value from past reconstructed values:\n",
        "    P=np.dot(np.flipud(xrek[n-L+np.arange(L)]), h)\n",
        "    #quantize and de-quantize e to step-size 0.05 (mid tread):\n",
        "    e[n]=np.round((x[n]-P)/quantstep)*quantstep;\n",
        "    #Decoder in encoder:\n",
        "    #new reconstructed value:\n",
        "    xrek[n]=e[n]+P;\n",
        "    #LMS update rule:\n",
        "    h = h + 1.0* e[n]*np.flipud(xrek[n-L+np.arange(L)])\n",
        "\n",
        "print( \"Mean squared prediction error:\", np.dot(e, e) /np.max(np.size(e)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScGWeNXdkAsk"
      },
      "source": [
        "print (\"Compare that with the mean squared signal power:\", np.dot(x.transpose(),x)/np.max(np.size(x)))\n",
        "print (\"The Signal to Error ratio is:\", np.dot(x.transpose(),x)/np.dot(e.transpose(),e))\n",
        "display(ipd.Audio(e, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuOcO-OfkAsm"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x)\n",
        "plt.plot(e,'r')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Normalized Sample')\n",
        "plt.title('Least Mean Squares (LMS) Online Adaptation')\n",
        "plt.legend(('Original','Prediction Error'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84MXN_8kAsn"
      },
      "source": [
        "# Decoder\n",
        "h = np.zeros(L);\n",
        "xrek = np.zeros(np.size(x));\n",
        "for n in range(L, len(x)):\n",
        "    if n> 41405 and n< 41408:\n",
        "        print('n:',n)\n",
        "        print (\"encoder h: \", h, \"\\ne=\", e)\n",
        "    P=np.dot(np.flipud(xrek[n-L+np.arange(L)]), h)\n",
        "    xrek[n] = e[n] + P \n",
        "    #LMS update:\n",
        "    h = h + 1.0 * e[n]*np.flipud(xrek[n-L+np.arange(L)]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvDZeWiWkAso"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(xrek)\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Normalized Sample')\n",
        "plt.title('The Reconstructed Signal')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y_WjLgDkAsp"
      },
      "source": [
        "display(ipd.Audio(xrek, rate = samplerate ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-0yJOGZkAsr"
      },
      "source": [
        "**Observe:** Because of the quantization, the prediction error now clearly increased.\n",
        "\n",
        "**Observe:** The signal is now **fully decoded**, even with quantization, although with a little noise, which was to be expected. But we can avoid the noise by reducing the quantization step size.\n",
        "\n",
        "Observe that this structure for the **decoder in the encoder also applies** to the **other prediction methods**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6vAKPckAsr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}